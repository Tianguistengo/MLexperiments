https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inline

np.random.seed(2)

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import itertools

from keras.utils.np_utils import to_categorical # convert to one-hot-encoding
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from keras.optimizers import RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau


sns.set(style='white', context='notebook', palette='deep')


---------------------------------------------

-The computer does not see the image, it sees an arry of numbers

- [red,green,blue] that's the order, so [0,1,0] it's only green.

-low numbers==darker, high numbers==brighter

"Neural networks expect the labels of classes in a dataset to be organized in a ONE-HOT ENCODER manner: 
each row in the array contains zeros in all columns, except the column corresponding to a unique label, which is set to 1.

-
# Reshape test data
test_data = test_data.reshape(10, 784)

# Evaluate the model
model.evaluate(test_data, test_labels)

-the KERNEL defines the feature that we are looking for
kernel=np.array([-1,1])

After the convolution is done (with a kernel that tells it what to look for),
the resulting array is called a ----- "FEATURE MAP"-----,
because it contains a map of the locations in the image that match the features represented by the kernel.

-The convolution of an image with a kernel 
summarizes a part of the image as the sum of the multiplication of that part of the image with the kernel.

-The output of each unit in this layer is a convolution of a kernel over the previous layer 
(if it's the first layer then its over the image input).

-A normal dense layer has one weight for each pixel in the image,
but a convolutional layer, has only one weight for each pixel IN THE KERNEL.

- the FLATTEN layer, acts as a connector between the convolution and dense layer.
The convolution layer hands the feature map and the flatten layer gives it to the dense layer(which acts as an output layer
with the softmax activation function).

-Convolutional networks for classification are constructed from a sequence of convolutional layers (for image processing) 
and fully connected (Dense) layers (for readout). 

"
-# Initialize the model object
model = Sequential()

# Add a convolutional layer
model.add(Conv2D(10, kernel_size=3, activation='relu', 
               input_shape=(img_rows,img_cols,1)))   ----> the one is for the channel( 1 in this case = B/W)
               
 # Compile the model 
model.compile(optimizer='adam', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

# Fit the model on a training set
model.fit(train_data, train_labels, 
          validation_split=0.2, 
          epochs=3, batch_size=10)
          
 -muy bueno para entender una nueva network 
 -------------------------->  a description of the model ---->  model.summary()
          
   - "one of the challenges in fitting neural networks is the --large number of parameters--,
   one way to mitigate this, is ---to summarize the output---
   of convolutional layers in a concise manner == ---> POOLING <--- operations

max pooling == summarize a group of pixels based on its maximal value (the brightest feature)
-----MaxPool2D---- after a conv layer
Convolution => Max pooling => Convolution => Flatten => Dense


---- there are of course tradeoffs of reducing the #s of parameters---

"As we have seen before, CNNs can have a lot of parameters. 
Pooling layers are often added between the convolutional layers of a neural network
to summarize their outputs in a condensed manner, 
and reduce the number of parameters in the next layer in the network. This can help us 
if we want to train the network more rapidly, 
----or if we don't have enough data----- to learn a very large number of parameters.

The resulting image is smaller, but ---retains the salient features in every location-----.

A pooling layer can be described as a particular kind of convolution. 
For every window in the input it finds the maximal pixel value and passes only this pixel through.

# Result placeholder
result = np.zeros((im.shape[0]//2, im.shape[1]//2))

# Pooling operation
for ii in range(result.shape[0]):
    for jj in range(result.shape[1]):
        result[ii, jj] = np.max(im[ii*2:ii*2+2, jj*2:jj*2+2])
        
        model.add(MaxPool2D(2))     -->pooling over windows of 2x2



---------full example of conv net with MaxPool2D------------

# Result placeholder
result = np.zeros((im.shape[0]//2, im.shape[1]//2))

# Pooling operation
for ii in range(result.shape[0]):
    for jj in range(result.shape[1]):
        result[ii, jj] = np.max(im[ii*2:ii*2+2, jj*2:jj*2+2])


# Add a convolutional layer
model.add(Conv2D(15, kernel_size=2, activation='relu', 
                 input_shape=(img_rows, img_cols, 1)))

# Add a pooling operation
model.add(MaxPool2D(2))

# Add another convolutional layer
model.add(Conv2D(5, kernel_size=2, activation='relu'))

# Flatten and feed to output layer
model.add(Flatten())
model.add(Dense(3, activation='softmax'))
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Fit to training data
model.fit(train_data,train_labels,validation_split=0.2,epochs=3,batch_size=10)

# Evaluate on test data 
model.evaluate(test_data,test_labels,batch_size=10)


---------------

How do we use the best parameters BEFORE the network starts overfitting?

from keras.callbacks import ModelCheckpoint
(stores the weights of a network at the end of each epoch of learning)
{will only overwrite the weights if the validation loss decreases}
[if the network overfits, the weights will be stored for the epoch at which validaton loss was the smallest)

the checkpoint object is stored in a list
and passes as input when fitting the model

to use the best weights learned, we need to initialize the model again
# Load the weights from file
model.load_weights('weights.hdf5')

# Predict from the first three images in the test data
model.predict(test_data[:3])




-----Plot the learning curves

import matplotlib.pyplot as plt

# Train the model and store the training object
training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)

# Extract the history from the training object
history = training.history

# Plot the training loss 
plt.plot(history['loss'])
# Plot the validation loss
plt.plot(history['val_loss'])

# Show the figure
plt.show()


------> PADDING
Padding does something pretty clever to solve this: 
pad the edges with extra, “fake” pixels (usually of value 0, hence the oft-used term “zero padding”).
This way, the kernel when sliding can allow the original edge pixels to be at its center, 
while extending into the fake pixels beyond the edge, producing an output the same size as the input.





