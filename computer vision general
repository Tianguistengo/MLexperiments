Part of the problem is a bottleneck at the heart of traditional sensors, which capture a huge amount of visual data, 
regardless of whether or not it is useful for classifying an image. Crunching all that data slows things down.

--------------------http://szeliski.org/Book/

A crash course on NumPy for images (skimages)
https://scikit-image.org/docs/dev/user_guide/numpy_images.html


--------------------------------------------------------------------------------------------

-In Image processing, *blob detection* refers to modules that are aimed at detecting points and/or regions in the image 
that differ in properties like 
brightness or color compared to the surrounding.
... It is used to obtain regions of interest for further processing.

-Pyramid, or pyramid representation, is a type of multi-scale signal representation developed by the computer vision, 
image processing and signal processing communities, in which a signal or an image is subject to 
repeated smoothing and subsampling. 
Pyramid representation is a predecessor to scale-space representation and multiresolution analysis. 

Stereo matching is the process of taking two or more images and estimating a 3D model of the scene 
by finding matching pixels in the images and converting their 2D positions into 3D depths.



-"For many applications of image processing, color information doesn't help us
identify important edges or other features." exceptions apply (for faces, colour usually is a good indicator, apparently).

-Thresholding 
(separating between foreground and background) is the simplest method of image segmentation.
+ You should use local thresholding instead of global if the image has a wide variation of background intensity.
+As we saw in the video, not being sure about what thresholding method to use isn't a problem.
In fact, scikit-image provides us with a function (from skimage.filters import try_all_threshold)
to check multiple methods and see 
for ourselves what the best option is. 
It returns a figure comparing the outputs of different global thresholding methods.

-A Gaussian filter can blur (reduce sharpness) an image to reduce noise and improve the likelihood of detecting something specific 
(e.g. edges, pero no creo que aplique a todo).

-Through the following code, you calculate the range of the pixels intensities in the histogram,
and so, the contrast of the image!

In [1]: np.min(clock_image)
Out[1]: 99

In [2]: np.max(clock_image)
Out[2]: 247

247-99=148 is the contrast

-# Use histogram equalization to improve the contrast
         xray_image_eq =  exposure.equalize_hist(chest_xray_image)
         
-"Amazing! You have increased the contrast of the image using an algorithm for local contrast enhancement,
that uses histograms computed over different tile regions of the image.
Local details can therefore be enhanced even in regions that are darker or lighter than the rest of the image."

-"Remember that aliasing is an effect that causes different signals, in this case pixels,
to become indistinguishable or distorted." (and hence anti-aliasing hace que no se distorsionen si las resize/rescale)
+anti aliasing preserves the quality (to an extent) but loses sharpness)

# Rescale with anti aliasing
rescaled_with_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=True, multichannel=True) multichannel means is a colour pic

-2 morphological operations"  (them both are useful to remove noise[among other benefits])
Dilation: adds pixels from the boundaries of objetcs
Erosion: removes pixels from the boundaries of objects
(pro tip, erosion is useful for removing minor white noise.)


-Inpainting 
is the process of reconstructing lost or deteriorated parts of images and videos.

-Denoising filters (total variation vs bilateral)
Since we prefer to preserve the edges in the image, we'll use the bilateral denoising filter.
total variation reduces noise by reducing variance

-The total amount of pixel is its resolution. Given by Height×Width.

Use .shape from NumPy to check the width and height of the image.

In [1]: np.shape(face_image)
Out[1]: (265, 191, 3)

face_image is 265 * 191 = 50,615 pixels


- Superpixel Segmentation (create pixel regions on the image).
You reduced the image from 50,615 pixels to 400 regions! 
Much more computationally efficient for, for example, face detection ML models.
(how much quality, important info, do we lose?)

# Obtain the segmentation with 400 regions
segments = slic(face_image, n_segments= 400)

# Put segments ON TOP of original image to compare
segmented_image = label2rgb(segments,face_image, kind='avg')  tienes que poner primero segmnets y luego face_image

- A contour 
is an outline formed by multiple points joined together.


-Representing an image by its edges 
has the advantage that the amount of data is reduce significantly while retaining most of the image information,
like the shapes. (((mmmmm most?)

-"Canny"== standard edge detection method

If we want to detect less edges (say, just the outer edge of a coin and not the inside)
we can increase the Gaussian filter to add more noise and detect less edges.
In the canny function, this can be accessed by the sigma= 

(the bigger the sigma value [Gaussian filter], the less edges are detected)

-Harris corner detection (popoular corner detection method)

-Make processes more computationally efficient with 
unsupervised superpixel segmentation. 


-The matplotlib function imshow() 
creates an image from a 2-dimensional numpy array. 
The image will have one square for each element of the array. 
The color of each square is determined by the value of the corresponding array element and the color map used by imshow() 


-Video content analysis (also video content analytics, VCA)
is the capability of automatically analyzing video to detect and determine temporal and spatial events.

-"What is a watermark?

Originally a watermark is a more or less transparent image or text that has been applied to a piece of paper,
another image to either protect the original image, or to make it harder to copy the item 
e.g. money watermarks or stamp watermarks.

-"
Inpainting is the process of ---reconstructing lost or deteriorated parts of images and videos---. 
In the museum world, in the case of a valuable painting, this task would be carried out by a skilled art conservator
or art restorer. In the digital world,
inpainting refers to the application of sophisticated algorithms
to replace lost or corrupted parts of the image data

-The Fourier transform (FT) decomposes a function (often a function of time, or a signal) into its constituent frequencies. 
A special case is the expression of a musical chord in terms of the volumes and frequencies of its constituent notes. 
The term Fourier transform refers to both the frequency domain representation
and the mathematical operation that 
associates the frequency domain representation to a function of time. 

- Point spread function

"
Assume we have a ‘point’ source, or a source that is far smaller than the maximum resolution (a pixel).
When we take an image of it, it will ‘spread’ over an area. 
To quantify that spread, we can define a ‘function’. 
This is how the point spread function or the PSF of an image is defined. 

This ‘spread’ can have various causes, for example in ground based astronomy, due to the atmosphere.
In practice we can never surpass the ‘spread’ due to the diffraction of the lens aperture.
Various other effects can also be quantified through a PSF. 
For example, the simple fact that we are sampling in a discrete space, namely the pixels, 
also produces a very small ‘spread’ in the image.

Convolution is the mathematical process by which we can apply a ‘spread’ to an image,
or in other words blur the image, see Convolution process. 
The Brightness of an object should remain unchanged after convolution, see Flux Brightness and magnitude. 
Therefore, it is important that the sum of all the pixels of the PSF be unity. 
The PSF image also has to have an odd number of pixels on its sides so one pixel can be defined as the center.


-Shape completion, the problem of --estimating the complete geometry of objects from partial observations--,
lies at the core of many vision and robotics applications.
In this work, we propose Point Completion Network (PCN), a novel learning-based approach for shape completion. 
