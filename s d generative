https://www.quantamagazine.org/how-artificial-intelligence-is-changing-science-20190311/

But some scientists are arguing that the latest techniques in machine learning and AI 
represent a fundamentally new way of doing science.

One such approach, known as generative modeling, can help 
>>identify the most plausible theory among competing explanations for observational data, 
based solely on the data, and, importantly, 
>>without any preprogrammed knowledge of what physical processes might be at work in the system under study. 
Proponents of generative modeling see it as novel enough t
o be considered a potential “third way” of learning about the universe.

Traditionally, we’ve learned about nature through 1. observation. 
Think of Johannes Kepler poring over Tycho Brahe’s tables of planetary positions 
and trying to discern the underlying pattern. (He eventually deduced that planets move in elliptical orbits.)

Science has also advanced through 2. simulation. 
An astronomer might model the movement of the Milky Way and its neighboring galaxy, Andromeda, 
and predict that they’ll collide in a few billion years.

Both observation and simulation help scientists generate hypotheses that can then be tested with further observations. 
3. Generative modeling differs from both of these approaches.

“It’s basically a third approach, between observation and simulation,” 
says Kevin Schawinski, an astrophysicist 
>>>>>>>>>>“It’s a different way to attack a problem.”

>>>Discovery by Generation

>> Essentially, generative modeling asks 
how likely it is, 
given condition X, 
that you’ll observe outcome Y.

(GANs). After adequate exposure to training data, a GAN can repair images that have damaged or >> missing pixels, 
or they can make blurry photographs sharp. They learn to >> infer the missing information by means of a competition 
(hence the term “adversarial”).
One part of the network, known as the generator, generates fake data, 
while a second part, the discriminator, tries to distinguish fake data from real data. 
As the program runs, both halves get progressively better.

More broadly, generative modeling takes sets of data (typically images, but not always) 
and breaks each of them down into a set of basic, abstract building blocks 
— scientists refer to this as the data’s “latent space.”
The algorithm manipulates elements of the latent space to see how this affects the original data,
and this helps uncover physical processes that are at work in the system.

 Their model created artificial data sets as a way of testing hypotheses about physical processes. 
 
 First, the galaxy images were reduced to their latent space; 
 then, Schawinski could tweak one element of that space 
 in a way that corresponded to a particular change in the galaxy’s environment — the density of its surroundings, for example.
 >>Then he could re-generate the galaxy and see what differences turned up.
 >>“So now I have a hypothesis-generation machine,” 
 This matches existing observations about galaxies, Schawinski said. 
 >>>>The question is  why this is so.

The next step, Schawinski says, has not yet been automated:
“I have to come in as a human, and say, ‘OK, what kind of physics could explain this effect?’
” For the process in question, there are two plausible explanations"
>>>>>With a generative model, both ideas can be put to the test.

Using generative modeling, astrophysicists could investigate how galaxies change 
when they go from low-density regions of the cosmos to high-density regions,
and what physical processes are responsible for these changes.

>>The approach is related to traditional simulation, but with critical differences. 
>A simulation is “essentially assumption-driven,” Schawinski said. 
“The approach is to say, ‘I think I know what the underlying physical laws are that give rise to everything 
that I see in the system.’ So I have a recipe for star formation, I have a recipe for how dark matter behaves, and so on.
I put all of my hypotheses in there, and I let the simulation run. And then I ask: Does that look like reality?” 
What he’s done with generative modeling, he said, is “in some sense, exactly the opposite of a simulation.
>>We don’t know anything; we don’t want to assume anything. We want the data itself to tell us what might be going on.”

For David Hogg,
the technique is impressive but ultimately just > a very sophisticated way of extracting patterns from data
— which is what astronomers have been doing for centuries. (tal vez no hay nada de malo con eso?)
In other words, it’s an advanced form of observation plus analysis.
 “I don’t think it’s a third way,” he said recently. 
 “I just think we as a community are becoming far more sophisticated about how we use the data.
 In particular, we are getting much better at comparing data to data.
 But in my view, my work is still squarely in the observational mode.”

it’s crucial that neural networks deliver not only results, but also error bars to go along with them,
as every undergraduate is trained to do. 
In science, if you make a measurement and don’t report an estimate of the associated error,
no one will take the results seriously, he said.

---------------

------->Playing with GANs

from the batch


Generative adversarial networks don’t just produce pretty pictures. They can build world models, too.

What’s new: A GAN generated a fully functional replica of the classic video game Pac-Man. 
Researchers from Nvidia, MIT, the University of Toronto, and Vector Institute developed GameGAN
to celebrate the original Pac-Man's 40th anniversary. 
The company plans to release the code in a few months.

How it works: GameGAN learned to reproduce the game by watching it in action for 50,000 hours. 
During gameplay, the system synthesizes the action frame by frame using three neural networks. 

    An LSTM-style network learned how user actions change the game's state.
    For example, pressing the system's joystick equivalent upward moves the Pac-Man character forward one space.
    
    A network inspired by neural Turing machines allows the system to store information about previously generated frames. 
    In a maze game, retracing your steps should look familiar, and that would be difficult without memory.
    
    Based on the memory, updated game state, and latest user action, GameGAN's generator produces the next frame. 

Behind the news: While Nvidia is the first to use a generative adversarial network to reproduce a video game,
other researchers have used machine learning for this purpose.

    An earlier model from Georgia Tech learns approximate representations of classic titles to create new games.
    The Metacreation Lab at Simon Fraser University is working on models that generate new levels for existing games.
    Researchers from Queen Mary University trained a neural network to duplicate a video game’s underlying mechanics
    by observing pixels.

Yes, but: Compared to the original arcade game, 
Pac-Man’s GAN-driven twin requires orders of magnitude more computation to run.

Why it matters: Autonomous systems such as self-driving cars and robots are often trained in elaborate simulators. 
Nvidia hopes that GAN-based sims can save time and money.

We’re thinking: Fifty thousand hours is an awful lot of Pac-Man — or anything else! 
Simulation makes it possible to amass training data that would be virtually impossible to collect in the real world. 
It's also a crutch that leads researchers to develop algorithms 
that work well in simulated environments but are hard to generalize to real-world conditions. 

Until better small-data algorithms emerge, GAN-based simulation looks like an exciting new direction.

-----------

related to GANs:

It takes two to invent anything.
The one makes up combinations; 
the other chooses, recognizes what he wishes and what is important to him in the mass of the things which the former has imparted to him.

Paul Valéry 

Quoted by Jacques Hadamard 
— The Psychology of Invention in the Mathematical Field, p. 30, Princeton University Press, Princeton, NJ, 1945

















