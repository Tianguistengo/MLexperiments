Bengio, goodfellow, courville,

p. 162
Other tasks, that cannot be described as associating one vector to another, 
or that are diﬃcult enough that a person would require time to think and reﬂect in order to accomplish the task, 
remain beyond the scope of deep learning for now.

5.10 Building a Machine Learning Algorithm
Nearly all deep learning algorithms can be described as particular instances of
a fairly simple recipe: combine 
a speciﬁcation of a dataset, 
a cost function, 
an optimization procedure 
and a model.

------------
Computational limits of deep learning

https://www.csail.mit.edu/news/computational-limits-deep-learning

A new project led by MIT researchers argues that deep learning is reaching its computational limits, 
which they say will result in one of two outcomes: 

1. deep learning being forced towards less computationally-intensive methods of improvement, 
2. or else machine learning being pushed towards techniques that are more computationally-efficient than deep learning.

----------------------------

https://www.newyorker.com/culture/annals-of-inquiry/the-mechanical-muse

The history of intelligent machines is one of moving goalposts:
Sure, a machine can do this, but can it do that? 
The “that” is often an achievement that strikes us as strongly connected to emotion—that seems especially human.

--------------------
https://www.technologyreview.com/2017/09/29/67852/is-ai-riding-a-one-trick-pony/

 What we know about intelligence is nothing against the vastness of what we still don’t know.
 
A real intelligence doesn't break when you slightly change the requirements
of the problem it's trying to solve.

How you might get a computer to work that way: to fluidly apply what it already knows to new tasks, 
to quickly bootstrap its way from knowing almost nothing about a new domain to being an expert.

For decades, backprop was cool math that didn’t really accomplish anything.
As computers got faster and the engineering got more sophisticated, suddenly it did. 
He hopes the same thing might happen with his own work and that of his students, “but it might take another couple decades.”

Eyal Dechter
Essentially, it is a procedure he calls the “exploration–compression” algorithm.
It gets a computer to function somewhat like a programmer who builds up a library of reusable, modular components
on the way to building more and more complex programs. 
Without being told anything about a new domain, 
the computer tries to structure knowledge about it just by playing around, 
consolidating what it’s found, and playing around some more, the way a human child does.

As for Hinton, he is convinced that overcoming AI’s limitations involves building
“a bridge between computer science and biology.”
Backprop was, in this view, a triumph of biologically inspired computation; 
the idea initially came not from engineering but from psychology. So now Hinton is trying to pull off a similar trick.

Neural networks today are made of big flat layers, 
but in the human neocortex real neurons are arranged not just horizontally into layers but vertically into columns.
Hinton thinks he knows what the columns are for—in vision, for instance, 
they’re crucial for our ability to recognize objects even as our viewpoint changes. 
So he’s building an artificial version—he calls them “capsules”—to test the theory.
So far, it hasn’t panned out; the capsules haven’t dramatically improved his nets’ performance.
But this was the same situation he’d been in with backprop for nearly 30 years.

“This thing just has to be right,” he says about the capsule theory, laughing at his own boldness.
“And the fact that it doesn’t work is just a temporary annoyance.”

-------------
https://www.huffpost.com/entry/artificial-intelligence_b_5174265
Hawking, Tegmark, etc..

The potential benefits are huge; 
everything that civilization has to offer is a product of human intelligence;
>we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide,
but the eradication of war, disease, and poverty would be high on anyone’s list.
>Success in creating AI would be the biggest event in human history.
Unfortunately, it might also be the last, unless we learn how to avoid the risks.

>Looking further ahead, there are no fundamental limits to what can be achieved:
there is no physical law precluding particles from being organized 
in ways that perform even more advanced computations than the arrangements of particles in human brains. 
>An explosive transition is possible, although it may play out differently than in the movie(s)

One can imagine such technology outsmarting financial markets, 
out-inventing human researchers, out-manipulating human leaders, and developing weapons we cannot even understand. 
Whereas the short-term impact of AI depends on who controls it, 
the long-term impact depends on whether it can be controlled at all.

So, facing possible futures of incalculable benefits and risks, 
the experts are surely doing everything possible to ensure the best outcome, right? Wrong.
All of us — not only scientists, industrialists and generals — should ask ourselves 
what can we do now to improve the chances of reaping the benefits and avoiding the risks.

-------

Daniel Dennett

We don't need artificial conscious agents. We need intelligent tools.

Yo iria un poco mas alla de conscious, no necesitamos un AI que se adapte a todos los domains
y generalice con todo, podemos aprovechar lo que existe, nuevas cosas vendran pronto de todas maneras












