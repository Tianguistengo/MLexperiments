The Master Algorithm: Here, the books’ central hypothesis is presented:

    ‘All knowledge — past, present, and future — 
    can be deduced from data 
    by a single, universal learning algorithm.’

-----------------
https://blogs.sciencemag.org/pipeline/archives/2019/10/02/automated-discovery


I think that the classification scheme in the paper is a useful one to start to deal with these objections.
They divide scientific discoveries impacted by automation into three categories: 

1. physical matter (a drug candidate, a new metal alloy, new crystal form, etc.),

2. processes (such as new chemical reactions), 

3. models (new laws, rules of thumb, correlations, and connections). 

The authors argue that all three of these are fundamentally 
>>search problems
– they just differ in the knowledge space being searched, 
which is a process of validation and feedback. 

That holds whether you’re talking about a hypothesis-first (Popperian) mode of discovery 
or an observation-first (Baconian) one; 
the difference between the two is (to a large extent) 
where you enter that cycle of observation and experimentation.

The paper makes the key point that in every example of machine-aided discovery so far, 
>>the search space has been far larger 
than what was (or even could be) explored. 

When you look closer, >>>>>    it’s human input that has narrowed the terms and the search space.

The authors also note the three factors that are enabling automation in all of these classes 
– access to large amounts of data, 
-the increasing computing power to process it all, 
-the advances in hardware to mechanically manipulate the physical tools of experimentation

Now one gets to the question of just how automated/autonomous things really are (or really can get):

    Here, we propose a set of questions to ask when evaluating the extent to which a discovery process or workflow is autonomous: 
    
    (i) How broadly is the goal defined? 
    (ii) How constrained is the search/design space? 
    (iii) How are experiments for validation/feedback selected? 
    (iv) How superior to a brute force search is navigation of the design space?
    (v) How are experiments for validation/feedback performed? 
    (vi) How are results organized and interpreted? 
    (vii) Does the discovery outcome contribute to broader scientific knowledge?


---------------
Maithra Raghu and Eric Schmid

1. From Predictions to Understanding 

One fundamental difference between scientific questions and core machine learning problems is the 
emphasis of science on understanding the underlying mechanisms.

>>interpretability and representational analysis,
a set of techniques focused on gaining insights into the internals of the end-to-end system: 
identifying important features in the data,
understanding its effect on model outputs 
and discovering properties of model hidden representations. 

These are very important for many scientific problems which emphasise understanding
over predictive accuracy, 
and may be of broader interest for e.g. aiding model debugging and preemptively identifying failure modes.

There has been significant work on both tools to understand 
what features of the input are most critical to the output prediction, 
as well as techniques to 
>>> directly analyze the hidden representations 
of the neural network models, 
which can reveal important properties of the underlying data.

2. Complex Transformations of Input Data 

In many scientific domains, the amount of generated data, particularly visual data 
(e.g. fluorescence microscopy, spatial sequencing, specimen videos [177, 97]) has grown dramatically, 
and there is an urgent need for 
efficient analysis 
and automated processing. 
Deep learning techniques, which are capable of many complex transformations of data, 
can be highly effective for such settings, for example, using a deep neural network based segmentation model to automatically
identify the nuclei in images of cells, 
or a pose estimation system to rapidly label behaviors seen in videos of mice for neuroscience analysis.

3. Prediction Problems
We can also think of this predictive use case as 
>>>>>getting the model to learn a target function,
in our example, mapping from input visual features to the cancer/no cancer output.

Using deep learning in this way also encapsulates 
>> settings where the target function is very complex, 
with no mathematical closed form or logical set of rules that describe how to go from input to output. 

For instance, we might use a deep learning model to (black-box) simulate a complex process
(e.g. climate modelling), that is very challenging to explicitly model.


6.2.4 Co-training

Another way to provide feedback on unlabelled data
is to train two (many) neural network models, >> each on a different view of the raw data.

For example, with text data, each model might see a different part of the input sentence. 
These models can then be given feedback to be maximally consistent with each other,
or with a different model which sees all of the data, 
or even used for self-training,
with each different model providing pseudo labels on the instances it is most confident on.

This post https://ruder.io/semi-supervised/ gives a nice overview of different co-training schemes.














